{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 15:20:21.014951: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 15:20:21.618303: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/cuda/lib:/usr/local/cuda/lib64:\n",
      "2023-04-21 15:20:21.618361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/cuda/lib:/usr/local/cuda/lib64:\n",
      "2023-04-21 15:20:21.618366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "import random\n",
    "import logging\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#nltk.download(\"punkt\")\n",
    "# Only log error messages\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "# Set random seed\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./esperberto-vocab.json', './esperberto-merges.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "\n",
    "paths = \"/home/john_zhang/EEG_NLP/flattened_list.txt\"\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])\n",
    "\n",
    "# Save files to disk\n",
    "tokenizer.save_model(\".\", \"esperberto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./esperberto/esperberto-vocab.json', './esperberto/esperberto-merges.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model(\"./esperberto\", \"esperberto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "s = 1000\n",
    "TOKEN_LENGTH = 30 #ms\n",
    "WORD_LENGTH = 10*s #s\n",
    "SENTENCE_LENGTH = 100*s #s\n",
    "\n",
    "TOKENIZER_BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('sam_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_data, f)\n",
    "with open('../sam_dataset.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2052\n",
      "256\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "file_path = \"train.txt\"  # Path to the output file\n",
    "train_data1 = train_data[0:int(len(train_data)*0.8)]\n",
    "tmp = train_data[int(len(train_data)*0.8):]\n",
    "test_data1 = tmp[0:int(len(tmp)*0.5)]\n",
    "\n",
    "val_data1 = tmp[int(len(tmp)*0.5):]\n",
    "with open(file_path, \"w\") as file:\n",
    "    for row in train_data1:\n",
    "        # Convert each element in the row to a string and join them with a delimiter\n",
    "        line = \"\".join(str(elem) for elem in row)\n",
    "        file.write(line + \"\\n\")\n",
    "print(len(train_data1))\n",
    "file_path = \"test.txt\" \n",
    "with open(file_path, \"w\") as file:\n",
    "    for row in test_data1:\n",
    "        # Convert each element in the row to a string and join them with a delimiter\n",
    "        line = \"\".join(str(elem) for elem in row)\n",
    "        file.write(line + \"\\n\")\n",
    "print(len(test_data1))\n",
    "file_path = \"val.txt\" \n",
    "with open(file_path, \"w\") as file:\n",
    "    for row in val_data1:\n",
    "        # Convert each element in the row to a string and join them with a delimiter\n",
    "        line = \"\".join(str(elem) for elem in row)\n",
    "        file.write(line + \"\\n\")\n",
    "print(len(val_data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer.encode(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcout = 0\n",
    "num_ones = 0\n",
    "counts = []\n",
    "for i in range(len(train_data)):\n",
    "    for t in train_data[i]:\n",
    "        en = tokenizer.encode(t)\n",
    "        num_ones += tf.reduce_sum(tf.cast(tf.equal(en.ids, 1), tf.int32))\n",
    "        counts.append(len(en.ids))\n",
    "        if len(en.ids) > maxcout:\n",
    "            maxcout = len(en.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(num_ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 137355 artists>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "  \n",
    "# creating the dataset\n",
    "\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(range(len(counts)),counts, color ='maroon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464.4852244184777"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(counts)/len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"/home/john_zhang/EEG_NLP/llm_for_eeg/esperberto/esperberto-vocab.json\",\n",
    "    \"/home/john_zhang/EEG_NLP/llm_for_eeg/esperberto/esperberto-merges.txt\",\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2/tok2-vocab.json', 'tok2/tok2-merges.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.enable_truncation(max_length=512)\n",
    "tokenizer.save_model(\"tok2\", \"tok2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for '/home/john_zhang/EEG_NLP/llm_for_eeg/tok2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/john_zhang/EEG_NLP/llm_for_eeg/tok2' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertTokenizer\n\u001b[1;32m      2\u001b[0m tokenizer_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/john_zhang/EEG_NLP/llm_for_eeg/tok2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(tokenizer_folder, return_special_tokens_mask\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, max_length\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m)  \n\u001b[1;32m      6\u001b[0m \u001b[39m#tokenizer.save_pretrained(tokenizer_folder)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1789\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   1784\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load following files from cache: \u001b[39m\u001b[39m{\u001b[39;00munresolved_files\u001b[39m}\u001b[39;00m\u001b[39m and cannot check if these \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1785\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1786\u001b[0m     )\n\u001b[1;32m   1788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(full_file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m full_file_name \u001b[39min\u001b[39;00m resolved_vocab_files\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m-> 1789\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   1790\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load tokenizer for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1791\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1792\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1793\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining all relevant files for a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1794\u001b[0m     )\n\u001b[1;32m   1796\u001b[0m \u001b[39mfor\u001b[39;00m file_id, file_path \u001b[39min\u001b[39;00m vocab_files\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1797\u001b[0m     \u001b[39mif\u001b[39;00m file_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for '/home/john_zhang/EEG_NLP/llm_for_eeg/tok2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/john_zhang/EEG_NLP/llm_for_eeg/tok2' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer_folder = \"/home/john_zhang/EEG_NLP/llm_for_eeg/tok2\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_folder, return_special_tokens_mask=True, max_length=512)  \n",
    "\n",
    "#tokenizer.save_pretrained(tokenizer_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "tokenizer_folder = \"./bpe\"\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, return_special_tokens_mask=True, max_length=512)  \n",
    "\n",
    "#tokenizer.save_pretrained(tokenizer_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=52_000,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=1,\n",
    "    num_hidden_layers=1,\n",
    "    type_vocab_size=1,\n",
    "    hidden_size = 76,\n",
    "    intermediate_size = 307\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 76,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 307,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 1,\n",
       "  \"num_hidden_layers\": 1,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.28.0.dev0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 52000\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import RobertaModel\n",
    "\n",
    "model = RobertaModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4067903"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 14:47:36.645189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 14:47:37.925121: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/cuda/lib:/usr/local/cuda/lib64:\n",
      "2023-05-12 14:47:37.925199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/cuda/lib:/usr/local/cuda/lib64:\n",
      "2023-05-12 14:47:37.925206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.data.datasets because of the following error (look up to see its traceback):\n/home/john_zhang/.conda/envs/eeg_nlp/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: cudaGraphDebugDotPrint, version libcudart.so.11.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/site-packages/transformers/utils/import_utils.py:1119\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/site-packages/transformers/data/__init__.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m glue_compute_metrics, xnli_compute_metrics\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mprocessors\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     DataProcessor,\n\u001b[1;32m     29\u001b[0m     InputExample,\n\u001b[1;32m     30\u001b[0m     InputFeatures,\n\u001b[1;32m     31\u001b[0m     SingleSentenceClassificationProcessor,\n\u001b[1;32m     32\u001b[0m     SquadExample,\n\u001b[1;32m     33\u001b[0m     SquadFeatures,\n\u001b[1;32m     34\u001b[0m     SquadV1Processor,\n\u001b[1;32m     35\u001b[0m     SquadV2Processor,\n\u001b[1;32m     36\u001b[0m     glue_convert_examples_to_features,\n\u001b[1;32m     37\u001b[0m     glue_output_modes,\n\u001b[1;32m     38\u001b[0m     glue_processors,\n\u001b[1;32m     39\u001b[0m     glue_tasks_num_labels,\n\u001b[1;32m     40\u001b[0m     squad_convert_examples_to_features,\n\u001b[1;32m     41\u001b[0m     xnli_output_modes,\n\u001b[1;32m     42\u001b[0m     xnli_processors,\n\u001b[1;32m     43\u001b[0m     xnli_tasks_num_labels,\n\u001b[1;32m     44\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/site-packages/transformers/data/processors/__init__.py:16\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mglue\u001b[39;00m \u001b[39mimport\u001b[39;00m glue_convert_examples_to_features, glue_output_modes, glue_processors, glue_tasks_num_labels\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msquad\u001b[39;00m \u001b[39mimport\u001b[39;00m SquadExample, SquadFeatures, SquadV1Processor, SquadV2Processor, squad_convert_examples_to_features\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m DataProcessor, InputExample, InputFeatures, SingleSentenceClassificationProcessor\n",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/site-packages/transformers/data/processors/squad.py:34\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorDataset\n",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/site-packages/torch/__init__.py:229\u001b[0m\n\u001b[1;32m    228\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/john_zhang/.conda/envs/eeg_nlp/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: cudaGraphDebugDotPrint, version libcudart.so.11.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m LineByLineTextDataset\n\u001b[1;32m      3\u001b[0m \u001b[39m# dataset = LineByLineTextDataset(\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#     tokenizer=tokenizer,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#     file_path=\"../tmp_data.txt\",\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#     block_size=128,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m      9\u001b[0m dataset \u001b[39m=\u001b[39m LineByLineTextDataset(\n\u001b[1;32m     10\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[1;32m     11\u001b[0m     file_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput.txt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     block_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/site-packages/transformers/utils/import_utils.py:1109\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m   1108\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1109\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   1110\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1111\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/eeg_nlp/lib/python3.9/site-packages/transformers/utils/import_utils.py:1121\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1122\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1123\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1124\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.data.datasets because of the following error (look up to see its traceback):\n/home/john_zhang/.conda/envs/eeg_nlp/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: cudaGraphDebugDotPrint, version libcudart.so.11.0"
     ]
    }
   ],
   "source": [
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "# dataset = LineByLineTextDataset(\n",
    "#     tokenizer=tokenizer,\n",
    "#     file_path=\"../tmp_data.txt\",\n",
    "#     block_size=128,\n",
    "# )\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"output.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LineByLineTextDataset' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[39m.\u001b[39;49mkeys()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LineByLineTextDataset' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./EsperBERTo\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_gpu_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
